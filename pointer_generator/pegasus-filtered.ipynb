{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset gigaword (/tmp/xdg-cache/huggingface/datasets/gigaword/default/1.2.0/c518c578e42a6afe842b09e979ee2907ea42a12b57ba992fae9e9d7347825245)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import math\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"gigaword\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "entailed = pd.read_csv(\"../data/gigawordfiltered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n",
    "src_text = [text for i,text in enumerate(dataset['train']['document'][0:1057]) if entailed['index_keys'][i] == 1]\n",
    "target_text = [text for i,text in enumerate(dataset['train']['summary'][0:1057]) if entailed['index_keys'][i] == 1]\n",
    "print(len(src_text))\n",
    "print(len(target_text))\n",
    "\n",
    "model_name = 'google/pegasus-gigaword'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "\n",
    "#model = PegasusForConditionalGeneration.from_pretrained(model_name,return_dict=True,output_attentions=True,output_hidden_states=True).to(torch_device)\n",
    "\n",
    "train_data = tokenizer.prepare_seq2seq_batch(src_text, target_text, return_tensors=\"pt\", truncation=\"only_first\", padding=\"longest\", max_length=64)\n",
    "\n",
    "input_ids_train = train_data['input_ids']\n",
    "attention_masks_train = train_data['attention_mask']\n",
    "labels_train = train_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, PegasusConfig, modeling_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PegasusConfig.from_pretrained(model_name, output_hidden_states=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pega_copyback_model = PegasusForConditionalGeneration.from_pretrained(model_name, config=config).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "\n",
    "batch_size = 2\n",
    "dataloader_train = DataLoader(dataset_train,sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "\n",
    "#freezing the parameters\n",
    "# for param in pega_copyback_model.model.parameters():\n",
    "#     param.requires_grad = False\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, pega_copyback_model.parameters()),lr=5e-5)\n",
    "                  \n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8e622d20504423a23bcd1bf02d3448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=500.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 1\n",
      "\r",
      "Training loss: 4.699029082536698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=500.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 2\n",
      "\r",
      "Training loss: 0.6498430743142962\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 3', max=500.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 3\n",
      "\r",
      "Training loss: 0.4649288988262415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 4', max=500.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 4\n",
      "\r",
      "Training loss: 0.3308471296206117\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 5', max=500.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 5\n",
      "\r",
      "Training loss: 0.24092654418665915\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 6', max=500.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 6\n",
      "\r",
      "Training loss: 0.17421084063686432\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 7', max=500.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 7\n",
      "\r",
      "Training loss: 0.11855787629075348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 8', max=500.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 8\n",
      "\r",
      "Training loss: 0.09063395719486289\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 9', max=500.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 9\n",
      "\r",
      "Training loss: 0.06879149263561703\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 10', max=500.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 10\n",
      "\r",
      "Training loss: 0.0571554719399428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)  \n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    pega_copyback_model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for b in progress_bar:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        b = tuple(x.to(torch_device) for x in b)\n",
    "        \n",
    "        inputs = {'input_ids':      b[0],\n",
    "                  'attention_mask': b[1],\n",
    "                  'labels':         b[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = pega_copyback_model(**inputs)\n",
    "#         vocab_size =  outputs['logits'].shape[2]\n",
    "    \n",
    "        loss = outputs[0]#criterion(outputs.view(-1,vocab_size),b[2].view(-1))\n",
    "\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "#         torch.nn.utils.clip_grad_norm_(pega_copyback_model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(b))})\n",
    "         \n",
    "        \n",
    "    torch.save(pega_copyback_model.state_dict(), f'data/finetuned_filtered_pega_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pega_copyback_model.eval()\n",
    "\n",
    "tgt_text = tokenizer.batch_decode(pega_copyback_model.generate(train_data['input_ids'][[0],:].to(torch_device)))#, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['australian current account deficit narrows sharply on australian trade deficit narrows commodity price rise narrows oil price rise narrows in june quarter on commodity price riseunk_3']\n"
     ]
    }
   ],
   "source": [
    "print(tgt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Sentence: five-time world champion michelle kwan withdrew from the #### us figure skating championships on wednesday , but will petition us skating officials for the chance to compete at the #### turin olympics .\n",
      "Sample Sentence: k kwan seeks us skating officials help for turin olympics kwan withdraws wants to skate at least for right to be at beijingunk_3\n",
      "Source Sentence: us business leaders lashed out wednesday at legislation that would penalize companies for employing illegal immigrants .\n",
      "Sample Sentence: us us us business leaders blast anti-immigration us immigration bill as business leaders as us congress wants to punishes firms over hiring of illegal immigrants ;unk_3\n",
      "Source Sentence: general motors corp. said wednesday its us sales fell ##.# percent in december and four percent in #### with the biggest losses coming from passenger car sales .\n",
      "Sample Sentence: gm us sales in us down ##.# pct in us in gm says us sees ##.# pct in us sales drop in december # pctunk_3\n",
      "Source Sentence: several thousand people gathered on wednesday evening on the main square in zagreb for a public draw and an open air party to celebrate the croatian capital 's second chance to host the women 's slalom world cup .\n",
      "Sample Sentence: zagreb holds draw to celebrate second chance to bid to UNK to UNK to croatia to host women's slalom worldunk_3\n",
      "@@@@@@@@@@@@@@@@@@@ Rogue @@@@@@@@@@@@@@@@@@@@@@@\n",
      "\n",
      "{'rouge1': AggregateScore(low=Score(precision=0.1700157331999004, recall=0.5378745220057719, fmeasure=0.2560549396240145), mid=Score(precision=0.18720498993372775, recall=0.5806008297258298, fmeasure=0.27892959370325654), high=Score(precision=0.20579919316483303, recall=0.6229962031024531, fmeasure=0.30231505070401626)), 'rouge2': AggregateScore(low=Score(precision=0.06674476367413913, recall=0.23180067640692628, fmeasure=0.10233905406467186), mid=Score(precision=0.08115814205806118, recall=0.2759644660894659, fmeasure=0.12314334540814738), high=Score(precision=0.09619814133908516, recall=0.3189773358585857, fmeasure=0.14414495951847858)), 'rougeL': AggregateScore(low=Score(precision=0.15289498349992903, recall=0.48701411435786435, fmeasure=0.23075815178537065), mid=Score(precision=0.1684677616132626, recall=0.5246881313131314, fmeasure=0.25137548034991286), high=Score(precision=0.18571031515441289, recall=0.5657198502886003, fmeasure=0.2737571484766071)), 'rougeLsum': AggregateScore(low=Score(precision=0.15315291323404667, recall=0.4792628066378065, fmeasure=0.23018583440159263), mid=Score(precision=0.1687297232258066, recall=0.5253547979797979, fmeasure=0.25168827639986907), high=Score(precision=0.1843255158554469, recall=0.566862490981241, fmeasure=0.2728335491546018))}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "pega_copyback_model.eval()\n",
    "\n",
    "\n",
    "metric = load_metric(\"rouge\")\n",
    "\n",
    "src_text = dataset['validation']['document'][0:100]\n",
    "target_text = dataset['validation']['summary'][0:100]\n",
    "\n",
    "val_data = tokenizer.prepare_seq2seq_batch(src_text, target_text, return_tensors=\"pt\", truncation=\"only_first\", padding=\"longest\", max_length=64)\n",
    "\n",
    "input_ids_val = val_data['input_ids']\n",
    "attention_masks_val = val_data['attention_mask']\n",
    "labels_val = val_data['labels']\n",
    "\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "batch_size = 1\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size)\n",
    "\n",
    "\n",
    "shouldPrint = 0\n",
    "toPrint = 4\n",
    "with torch.no_grad():\n",
    "    for b in dataloader_val:        \n",
    "        b = tuple(x.to(torch_device) for x in b)\n",
    "        \n",
    "        inputs = {'input_ids':      b[0],\n",
    "                  'attention_mask': b[1],\n",
    "                  'labels':         b[2],\n",
    "                 }       \n",
    "        gen = tokenizer.batch_decode(pega_copyback_model.generate(inputs['input_ids']), skip_special_tokens=True)\n",
    "        if shouldPrint < toPrint:\n",
    "            print(\"Source Sentence:\", src_text[shouldPrint])\n",
    "            print(\"Sample Sentence:\", gen[0])\n",
    "            shouldPrint += 1 \n",
    "        ref = tokenizer.batch_decode(inputs['labels'])\n",
    "        metric.add_batch(predictions=gen, references=ref)\n",
    "\n",
    "print(\"@@@@@@@@@@@@@@@@@@@ Rogue @@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "print()\n",
    "        \n",
    "print(metric.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
