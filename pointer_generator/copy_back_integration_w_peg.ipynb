{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset gigaword (/tmp/xdg-cache/huggingface/datasets/gigaword/default/1.2.0/c518c578e42a6afe842b09e979ee2907ea42a12b57ba992fae9e9d7347825245)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"gigaword\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n",
    "src_text = dataset['train']['document'][0:10000]\n",
    "target_text = dataset['train']['summary'][0:10000]\n",
    "model_name = 'google/pegasus-gigaword'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# model = PegasusForConditionalGeneration.from_pretrained(model_name,return_dict=True,output_attentions=True,output_hidden_states=True).to(torch_device)\n",
    "# batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(torch_device)\n",
    "# batch2 = tokenizer.prepare_seq2seq_batch(target_text, truncation=True, padding='longest', return_tensors=\"pt\").to(torch_device)\n",
    "# translated = model.generate(**batch)\n",
    "train_data = tokenizer.prepare_seq2seq_batch(src_text, target_text, return_tensors=\"pt\", truncation=\"only_first\", padding=\"longest\")\n",
    "\n",
    "#tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['input_ids'] = train_data['input_ids'].to(torch_device)\n",
    "# train_data['attention_mask'] = train_data['attention_mask'].to(torch_device)\n",
    "# train_data['labels'] = train_data['labels'].to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = train_data['input_ids']\n",
    "attention_masks_train = train_data['attention_mask']\n",
    "labels_train = train_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[14937,  1034,   116,  ...,     0,     0,     0],\n",
      "        [  134,   583,   228,  ...,     0,     0,     0],\n",
      "        [73013,  2853,  2127,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  260,   117, 32078,  ...,     0,     0,     0],\n",
      "        [  154,   197,   110,  ...,     0,     0,     0],\n",
      "        [  126,  1034,   116,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[73013,   582,   728,  ...,     0,     0,     0],\n",
      "        [  134,   583,   228,  ...,     0,     0,     0],\n",
      "        [73013,  5446,   686,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 3834,  6010, 12752,  ...,     0,     0,     0],\n",
      "        [32577,   493, 23765,  ...,     0,     0,     0],\n",
      "        [94830,  1034,   116,  ...,     0,     0,     0]])}\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, PegasusConfig, modeling_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PegasusWithCopyBack(PegasusForConditionalGeneration):\n",
    "    def __init__(self, config):\n",
    "        super(PegasusWithCopyBack, self).__init__(config)\n",
    "        num_features = config.d_model\n",
    "        self.p_gen_w = nn.Linear(num_features*3,1)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.p_gen_w.bias = nn.Parameter(torch.ones(1))\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask=None,\n",
    "        decoder_input_ids=None,\n",
    "        decoder_attention_mask=None,\n",
    "        encoder_outputs=None,\n",
    "        past_key_values=None,\n",
    "        labels=None,\n",
    "        use_cache=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        out = super(PegasusWithCopyBack, self).forward(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            encoder_outputs=encoder_outputs,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            past_key_values=past_key_values,\n",
    "            use_cache=use_cache,\n",
    "            labels=labels,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        \n",
    "        hi = out['encoder_last_hidden_state'] # (batch_size x s_seq_len x model_size)\n",
    "        at = torch.mean(out['cross_attentions'][-1], dim=1) # (batch_size x t_seq_len x s_seq_len)        \n",
    "        st = out['decoder_hidden_states'][-1] # (batch_size x t_seq_len x model_size)\n",
    "        \n",
    "        if labels is not None:\n",
    "            dec = self.model.get_input_embeddings()(labels) # (batch_size x t_seq_len x model_size)\n",
    "        else:\n",
    "#             print(decoder_input_ids.shape)\n",
    "            dec = self.model.get_input_embeddings()(decoder_input_ids[:,[-1]])\n",
    "\n",
    "#         print((at@hi).shape)\n",
    "#         print(st.shape)\n",
    "#         print(dec.shape)\n",
    "        \n",
    "        p_gen = torch.sigmoid(self.p_gen_w(torch.cat((at @ hi,st,dec),dim=-1))) # (batch_size x t_seq_len x 1)\n",
    "        attn_dists = (1-p_gen)*at # (batch_size x t_seq_len x s_seq_len)\n",
    "        v_dist = p_gen * out['logits'] # (batch_size x t_seq_len x vocab_size)\n",
    "        \n",
    "\n",
    "        if input_ids is not None:            \n",
    "            src_ids = input_ids.unsqueeze(1).repeat(1, attn_dists.size(1), 1)   # (batch_size x 1 x s_seq_len)  \n",
    "        else:\n",
    "            src_ids = self.input_ids.unsqueeze(1).repeat(1, attn_dists.size(1), 1)   # (batch_size x 1 x s_seq_len)\n",
    "                \n",
    "        pred = v_dist.scatter_add(2, src_ids, attn_dists) #(batch_size x t_seq_len x vocab_size)\n",
    "\n",
    "        masked_lm_loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            # TODO(SS): do we need to ignore pad tokens in labels?\n",
    "            masked_lm_loss = loss_fct(pred.view(-1, self.config.vocab_size), labels.view(-1))\n",
    "        \n",
    "        if not return_dict:\n",
    "            output = (pred,) + out[1:]\n",
    "            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n",
    "        \n",
    "        return modeling_outputs.Seq2SeqLMOutput(\n",
    "            loss=masked_lm_loss,\n",
    "            logits=pred,\n",
    "            past_key_values=out.past_key_values,\n",
    "            decoder_hidden_states=out.decoder_hidden_states,\n",
    "            decoder_attentions=out.decoder_attentions,\n",
    "            cross_attentions=out.cross_attentions,\n",
    "            encoder_last_hidden_state=out.encoder_last_hidden_state,\n",
    "            encoder_hidden_states=out.encoder_hidden_states,\n",
    "            encoder_attentions=out.encoder_attentions,\n",
    "        )\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def generate(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        max_length=None,\n",
    "        min_length=None,\n",
    "        do_sample=None,\n",
    "        early_stopping=None,\n",
    "        num_beams=None,\n",
    "        temperature=None,\n",
    "        top_k=None,\n",
    "        top_p=None,\n",
    "        repetition_penalty=None,\n",
    "        bad_words_ids=None,\n",
    "        bos_token_id=None,\n",
    "        pad_token_id=None,\n",
    "        eos_token_id=None,\n",
    "        length_penalty=None,\n",
    "        no_repeat_ngram_size=None,\n",
    "        num_return_sequences=None,\n",
    "        attention_mask=None,\n",
    "        decoder_start_token_id=None,\n",
    "        use_cache=None,\n",
    "        **model_specific_kwargs\n",
    "    ):\n",
    "        self.input_ids = input_ids\n",
    "        return super(PegasusWithCopyBack, self).generate(\n",
    "            input_ids=input_ids,\n",
    "            max_length=max_length,\n",
    "            min_length=min_length,\n",
    "            do_sample=do_sample,\n",
    "            early_stopping=early_stopping,\n",
    "            num_beams=num_beams,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            bad_words_ids=bad_words_ids,\n",
    "            bos_token_id=bos_token_id,\n",
    "            pad_token_id=pad_token_id,\n",
    "            eos_token_id=eos_token_id,\n",
    "            length_penalty=length_penalty,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_start_token_id=decoder_start_token_id,\n",
    "            use_cache=use_cache,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PegasusConfig.from_pretrained(model_name, output_hidden_states=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusWithCopyBack were not initialized from the model checkpoint at google/pegasus-gigaword and are newly initialized: ['p_gen_w.weight', 'p_gen_w.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# pega_copyback_model = PegasusWithCopyBack(config, 1024).to(torch_device) \n",
    "pega_copyback_model = PegasusWithCopyBack.from_pretrained(model_name, config=config).to(torch_device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# out1 = pega_copyback_model(**train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "\n",
    "batch_size = 1\n",
    "dataloader_train = DataLoader(dataset_train,sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "\n",
    "#freezing the parameters\n",
    "# for param in pega_copyback_model.model.parameters():\n",
    "#     param.requires_grad = False\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, pega_copyback_model.parameters()),lr=5e-3)\n",
    "                  \n",
    "epochs = 30\n",
    "# #scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "#                                             num_warmup_steps=0,\n",
    "#                                             num_training_steps=len(dataloader_train)*epochs)\n",
    "# criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702928e8d6f94e119d6d190d8f8c3e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=1000.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 1\n",
      "\r",
      "Training loss: 3.946369893074036\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=1000.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 2\n",
      "\r",
      "Training loss: 3.1917985249757765\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 3', max=1000.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 3\n",
      "\r",
      "Training loss: 3.044819905728102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 4', max=1000.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 4\n",
      "\r",
      "Training loss: 3.1634563259482382\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 5', max=1000.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 5\n",
      "\r",
      "Training loss: 3.1400323094129563\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 6', max=1000.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 6\n",
      "\r",
      "Training loss: 3.078229182720184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 7', max=1000.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 7\n",
      "\r",
      "Training loss: 3.0514994572997094\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 8', max=1000.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 8\n",
      "\r",
      "Training loss: 3.0951524477005004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 9', max=1000.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 9\n",
      "\r",
      "Training loss: 3.0883041892051697\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 10', max=1000.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 10\n",
      "\r",
      "Training loss: 2.994523384451866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 11', max=1000.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 11\n",
      "\r",
      "Training loss: 2.909621947646141\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 12', max=1000.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 12\n",
      "\r",
      "Training loss: 2.8681880626380445\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 13', max=1000.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 13\n",
      "\r",
      "Training loss: 3.0351473249197007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 14', max=1000.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 14\n",
      "\r",
      "Training loss: 2.9427104002833366\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 15', max=1000.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 15\n",
      "\r",
      "Training loss: 2.9447396770715715\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 16', max=1000.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 16\n",
      "\r",
      "Training loss: 2.902334372282028\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 17', max=1000.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 17\n",
      "\r",
      "Training loss: 2.9050503029823305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841a4f29af5e4c17aac54fc6b25b196d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 18', max=1000.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    \n",
    "pega_copyback_model = pega_copyback_model.to(torch_device)   \n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    pega_copyback_model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for b in progress_bar:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        b = tuple(x.to(torch_device) for x in b)\n",
    "        \n",
    "        inputs = {'input_ids':      b[0],\n",
    "                  'attention_mask': b[1],\n",
    "                  'labels':         b[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = pega_copyback_model(**inputs)\n",
    "#         vocab_size =  outputs['logits'].shape[2]\n",
    "    \n",
    "        loss = outputs[0]#criterion(outputs.view(-1,vocab_size),b[2].view(-1))\n",
    "\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "#         torch.nn.utils.clip_grad_norm_(pega_copyback_model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(b))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'data/finetuned_pega_copyback_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(torch.argmax(outputs['logits'],dim=-1))\n",
    "    print(b[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pega_copyback_model.generate(train_data['input_ids'].to(torch_device)))\n",
    "print(train_data['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_text = tokenizer.batch_decode(pega_copyback_model.generate(train_data['input_ids'].to(torch_device)))#, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tgt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pega_copyback_model(train_data['input_ids'],)\n",
    "print(out['logits'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
