{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548d8c9d1f7241c7bbf90b8b9e97e86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1249.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "# pose sequence as a NLI premise and label as a hypothesis\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW\n",
    "from datasets import load_metric\n",
    "import torch.nn.functional as F\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"australia 's current account deficit shrunk by a record #.## billion dollars -lrb- #.## billion us -rrb- in the june quarter due to soaring commodity prices , figures released monday showed .\", 'australian current account deficit narrows sharply']\n"
     ]
    }
   ],
   "source": [
    "entailment_data = pd.read_csv('./gigaword1000entailment.csv')\n",
    "\n",
    "\n",
    "train_texts  = list(map(list, zip(entailment_data['document'], entailment_data['summary'])))\n",
    "# map to mnli mapping, entailment = 2, contradiction = 0\n",
    "print(train_texts[0])\n",
    "\n",
    "train_labels = [2 if label == 0 or label == 2 else 0 for label in entailment_data['label']]\n",
    "# train_labels = [2 if label == 0 else 0 for label in entailment_data['label']]\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e796cf96b24405bf8b559a8966c0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=908.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b9c01c2e7c4fa5961f62a0f93263f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de17441882c45cda47ac35cdb5b596e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09a110c42c449c2851039629abe24b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "\n",
    "train_encodings = tokenizer(train_texts, return_tensors='pt', truncation='only_first', padding =True)\n",
    "val_encodings = tokenizer(val_texts, return_tensors='pt', truncation='only_first', padding =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntailmentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = EntailmentDataset(train_encodings, train_labels)\n",
    "val_dataset = EntailmentDataset(val_encodings, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d6b770d6a444b28e49067cabbf2b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1629486723.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartForSequenceClassification: ['model.encoder.version', 'model.decoder.version']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n",
      "validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: {'accuracy': 0.785}\n",
      "epoch: 0\n",
      "validating\n",
      "acc: {'accuracy': 0.87}\n",
      "epoch: 1\n",
      "validating\n",
      "acc: {'accuracy': 0.87}\n",
      "epoch: 2\n",
      "validating\n",
      "acc: {'accuracy': 0.87}\n",
      "epoch: 3\n",
      "validating\n",
      "acc: {'accuracy': 0.87}\n",
      "epoch: 4\n",
      "validating\n",
      "acc: {'accuracy': 0.87}\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')#.to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# for param in model.bart.bart.parameters():\n",
    "#     param.requires_grad = False\n",
    "# Change batch size to 32 when we have access to many gpu's\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=1e-6)\n",
    "\n",
    "model.eval()\n",
    "print(\"validating\")\n",
    "with torch.no_grad():\n",
    "    losses = []\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        losses.append(outputs[0].detach().item())\n",
    "        preds = torch.argmax(F.softmax(outputs[1]), dim=1)\n",
    "        # need to check this\n",
    "        metric.add_batch(predictions=preds, references=labels)\n",
    "\n",
    "    acc = metric.compute()\n",
    "    print(\"acc:\", acc)\n",
    "\n",
    "val_perf = []\n",
    "for epoch in range(10):\n",
    "    print(\"epoch:\", epoch)\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        loss.mean().backward()\n",
    "        optim.step()\n",
    "\n",
    "    model.eval()\n",
    "    print(\"validating\")\n",
    "    with torch.no_grad():\n",
    "        losses = []\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            losses.append(outputs[0].detach().item())\n",
    "            preds = torch.argmax(F.softmax(outputs[1], dim=1), dim=1)\n",
    "            # need to check this\n",
    "            metric.add_batch(predictions=preds, references=labels)\n",
    "    \n",
    "        acc = metric.compute()\n",
    "        print(\"acc:\", acc)\n",
    "        val_perf.append(((sum(losses)/len(losses)), acc))\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7.731543998718262, {'accuracy': 0.87}), (2.2283348083496093, {'accuracy': 0.87}), (1.9416706848144532, {'accuracy': 0.87}), (1.7624877548217774, {'accuracy': 0.87}), (3.4690134811401365, {'accuracy': 0.87})]\n"
     ]
    }
   ],
   "source": [
    "print(val_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): BartForSequenceClassification(\n",
      "    (model): BartModel(\n",
      "      (shared): Embedding(50265, 1024, padding_idx=1)\n",
      "      (encoder): BartEncoder(\n",
      "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
      "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
      "        (layers): ModuleList(\n",
      "          (0): EncoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (1): EncoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (2): EncoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (3): EncoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (4): EncoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (5): EncoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (6): EncoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (7): EncoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (8): EncoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (9): EncoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (10): EncoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (11): EncoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (decoder): BartDecoder(\n",
      "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
      "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
      "        (layers): ModuleList(\n",
      "          (0): DecoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (encoder_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (1): DecoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (encoder_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (2): DecoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (encoder_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (3): DecoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (encoder_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (4): DecoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (encoder_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (5): DecoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (encoder_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (6): DecoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (encoder_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (7): DecoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (encoder_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (8): DecoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (encoder_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (9): DecoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (encoder_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (10): DecoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (encoder_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (11): DecoderLayer(\n",
      "            (self_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (encoder_attn): Attention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (classification_head): BartClassificationHead(\n",
      "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartForSequenceClassification: ['model.encoder.version', 'model.decoder.version']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1554, 0.8446]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli').to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "# label = \"history\"\n",
    "# premise = \"Napolean was exiled the Alba where he died of stomach cancer\"\n",
    "# hypothesis = f'This example is {label}.'\n",
    "\n",
    "premise = \"napolean and louis the 14th were two constrasting French figures whom once ruled the nation\"\n",
    "hypothesis = \"Comparison of two French Rulers and they were great\"\n",
    "\n",
    "\n",
    "\n",
    "# run through model pre-trained on MNLI\n",
    "x = tokenizer.encode(premise, hypothesis, return_tensors='pt', truncation='only_first', padding =True)\n",
    "logits = nli_model(x.to(device))[0]\n",
    "\n",
    "# we throw away \"neutral\" (dim 1) and take the probability of\n",
    "# \"entailment\" (2) as the probability of the label being true \n",
    "entail_contradiction_logits = logits[:,[0,2]]\n",
    "probs = entail_contradiction_logits.softmax(dim=1)\n",
    "prob_label_is_true = probs[:,1]\n",
    "\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([1, 2])\n",
      "tensor([[-2.0410, -0.3481]], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "torch.Size([1, 2])\n",
      "tensor([[0.1554, 0.8446]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([0.8446], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape)\n",
    "\n",
    "print(entail_contradiction_logits.shape)\n",
    "print(entail_contradiction_logits)\n",
    "\n",
    "print(probs.shape)\n",
    "print(probs)\n",
    "\n",
    "\n",
    "print(prob_label_is_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,   282,  1115, 48547,     8, 26120,   354,     5,   501,   212,\n",
      "            58,    80, 10759, 16136,   154,  1515,  2415,  2661,   683,  3447,\n",
      "             5,  1226,     2,     2, 48080,  4060,     9,    80,  1515,   248,\n",
      "           922,   268,     8,    51,    58,   372,     2]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset gigaword (/tmp/xdg-cache/huggingface/datasets/gigaword/default/1.2.0/c518c578e42a6afe842b09e979ee2907ea42a12b57ba992fae9e9d7347825245)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "giga_dataset = load_dataset(\"gigaword\", split='train[:1000]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.multiply(torch.rand((2,55,1)),torch.rand((2,55,1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /tmp/xdg-cache/huggingface/datasets/gigaword/default/1.2.0/c518c578e42a6afe842b09e979ee2907ea42a12b57ba992fae9e9d7347825245/cache-f50088200ce2f575.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['document', 'summary'],\n",
      "    num_rows: 1000\n",
      "})\n",
      "{'attention_mask': [tensor([1, 1, 1,  ..., 0, 0, 0])], 'input_ids': [tensor([   0,  102, 4193,  ...,    1,    1,    1])]}\n"
     ]
    }
   ],
   "source": [
    "giga_filtered_keys = pd.DataFrame()\n",
    "\n",
    "def mapper(examples):\n",
    "    return tokenizer([(examples['document'], examples['summary'])], return_tensors='pt', truncation=True, padding='max_length')\n",
    "print(giga_dataset)\n",
    "\n",
    "gigaset = giga_dataset.map(mapper)\n",
    "\n",
    "gigaset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "print(gigaset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])], 'input_ids': [tensor([[    0,   102,  4193,  ...,     1,     1,     1],\n",
      "        [    0,   415,   513,  ...,     1,     1,     1],\n",
      "        [    0,   102,  4193,  ...,     1,     1,     1],\n",
      "        [    0, 25515,   449,  ...,     1,     1,     1]])]}\n",
      "     index_keys\n",
      "0             1\n",
      "1             1\n",
      "2             1\n",
      "3             1\n",
      "4             1\n",
      "..          ...\n",
      "995           1\n",
      "996           1\n",
      "997           1\n",
      "998           1\n",
      "999           0\n",
      "\n",
      "[1000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "giga_filtered_keys = pd.DataFrame()\n",
    "\n",
    "giga_loader = DataLoader(gigaset, batch_size=4)\n",
    "\n",
    "# look into how it was bound together, something special is done\n",
    "print(next(iter(giga_loader)))\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_preds = []\n",
    "    for batch in giga_loader:\n",
    "        batch = {k: v[0].to(device) for k, v in batch.items()}\n",
    "#         input_ids = (batch['input_ids'][0].to(device), batch['input_ids'][1].to(device))\n",
    "#         attention_mask = (batch['attention_mask'][0].to(device), batch['attention_mask'][1].to(device))\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        outputs = nli_model(**batch)\n",
    "        preds = torch.argmax(F.softmax(outputs[0][:,[0,2]], dim=1), dim=1)\n",
    "        all_preds.append(preds)\n",
    "        \n",
    "    giga_filtered_keys['index_keys'] = torch.cat(all_preds, dim=0).cpu()\n",
    "    \n",
    "print(giga_filtered_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "108\n",
      "120\n",
      "142\n",
      "157\n",
      "160\n",
      "161\n",
      "175\n",
      "206\n",
      "234\n",
      "256\n",
      "278\n",
      "327\n",
      "341\n",
      "376\n",
      "377\n",
      "422\n",
      "444\n",
      "491\n",
      "495\n",
      "497\n",
      "518\n",
      "524\n",
      "555\n",
      "574\n",
      "585\n",
      "627\n",
      "645\n",
      "656\n",
      "661\n",
      "678\n",
      "680\n",
      "714\n",
      "725\n",
      "743\n",
      "755\n",
      "764\n",
      "777\n",
      "798\n",
      "802\n",
      "807\n",
      "817\n",
      "832\n",
      "847\n",
      "851\n",
      "866\n",
      "884\n",
      "938\n",
      "956\n",
      "958\n",
      "963\n",
      "983\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(giga_filtered_keys['index_keys']):\n",
    "    if item == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
